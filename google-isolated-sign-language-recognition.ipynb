{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":5325.073192,"end_time":"2023-03-23T00:16:08.917320","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-03-22T22:47:23.844128","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Google - Isolated Sign Language Recognition","metadata":{"_cell_guid":"59d398e0-ebca-4d80-86e6-82db24770d20","_uuid":"14e0ab19-6a57-4b94-b914-5919de708a3b","papermill":{"duration":0.007032,"end_time":"2023-03-22T22:47:33.682602","exception":false,"start_time":"2023-03-22T22:47:33.675570","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Machine Learning and Data Science Imports (basics)\nimport tensorflow as tf\nimport random\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nimport numpy as np\nimport pandas as pd\nimport os\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nfrom PIL import Image, ImageEnhance; Image.MAX_IMAGE_PIXELS = 5_000_000_000;\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport json\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nimport plotly.io as pio\npio.templates.default = \"simple_white\"\nimport math\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:45:19.964782Z","iopub.execute_input":"2023-09-12T15:45:19.965203Z","iopub.status.idle":"2023-09-12T15:45:20.012530Z","shell.execute_reply.started":"2023-09-12T15:45:19.965168Z","shell.execute_reply":"2023-09-12T15:45:20.011573Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# import data from specified data directory\ndef load_json_file(json_path):\n    with open(json_path, 'r') as f:\n        sign_map = json.load(f)\n    return sign_map\n\nclass CFG:\n    data_dir = \"/kaggle/input/asl-signs/\"\n    sequence_length = 12\n    rows_per_frame = 543\n    batch_size = 512\n\nROWS_PER_FRAME = 543\ndef load_relevant_data_subset(pq_path):\n    data_columns = ['x', 'y', 'z']\n    data = pd.read_parquet(pq_path, columns=data_columns)\n    n_frames = int(len(data) / ROWS_PER_FRAME)\n    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n    return data.astype(np.float32)\n    \nsign_map = load_json_file(CFG.data_dir + 'sign_to_prediction_index_map.json')\ntrain_data = pd.read_csv(CFG.data_dir + 'train.csv')\n\ns2p_map = {k.lower():v for k,v in load_json_file(CFG.data_dir + \"sign_to_prediction_index_map.json\").items()}\np2s_map = {v:k for k,v in load_json_file(CFG.data_dir + \"sign_to_prediction_index_map.json\").items()}\nencoder = lambda x: s2p_map.get(x.lower())\ndecoder = lambda x: p2s_map.get(x)\n\n# inspect data from one parquet file\ntrain_data.head()","metadata":{"_cell_guid":"b8e50450-6e94-4d31-ae40-fc171ed62132","_uuid":"757deb5b-e59a-4c24-a41b-1b6a6ac4f253","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":0.277462,"end_time":"2023-03-22T22:47:45.090781","exception":false,"start_time":"2023-03-22T22:47:44.813319","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:45:22.447171Z","iopub.execute_input":"2023-09-12T15:45:22.448077Z","iopub.status.idle":"2023-09-12T15:45:22.718114Z","shell.execute_reply.started":"2023-09-12T15:45:22.448032Z","shell.execute_reply":"2023-09-12T15:45:22.717144Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                            path  participant_id  sequence_id  \\\n0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n\n    sign  \n0   blow  \n1   wait  \n2  cloud  \n3   bird  \n4   owie  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>participant_id</th>\n      <th>sequence_id</th>\n      <th>sign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_landmark_files/26734/1000035562.parquet</td>\n      <td>26734</td>\n      <td>1000035562</td>\n      <td>blow</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_landmark_files/28656/1000106739.parquet</td>\n      <td>28656</td>\n      <td>1000106739</td>\n      <td>wait</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_landmark_files/16069/100015657.parquet</td>\n      <td>16069</td>\n      <td>100015657</td>\n      <td>cloud</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_landmark_files/25571/1000210073.parquet</td>\n      <td>25571</td>\n      <td>1000210073</td>\n      <td>bird</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_landmark_files/62590/1000240708.parquet</td>\n      <td>62590</td>\n      <td>1000240708</td>\n      <td>owie</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:45:36.607797Z","iopub.execute_input":"2023-09-12T15:45:36.610092Z","iopub.status.idle":"2023-09-12T15:45:36.623066Z","shell.execute_reply.started":"2023-09-12T15:45:36.610053Z","shell.execute_reply":"2023-09-12T15:45:36.620885Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(94477, 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Pipeline","metadata":{"papermill":{"duration":0.014962,"end_time":"2023-03-22T22:47:48.010443","exception":false,"start_time":"2023-03-22T22:47:47.995481","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.preprocessing import normalize\ntrain_x = np.load(\"/kaggle/input/gislr-feature-data/feature_data.npy\").astype(np.float32)\ntrain_y = np.load(\"/kaggle/input/gislr-feature-data/feature_labels.npy\").astype(np.uint8)\n\nN_TOTAL = train_x.shape[0]\nVAL_PCT = 0.1\nN_VAL   = int(N_TOTAL*VAL_PCT)\nN_TRAIN = N_TOTAL-N_VAL\n\nrandom_idxs = random.sample(range(N_TOTAL), N_TOTAL)\ntrain_idxs, val_idxs = np.array(random_idxs[:N_TRAIN]), np.array(random_idxs[N_TRAIN:])\n\nval_x, val_y = train_x[val_idxs], train_y[val_idxs]\ntrain_x, train_y = train_x[train_idxs], train_y[train_idxs]","metadata":{"papermill":{"duration":20.590633,"end_time":"2023-03-22T22:48:08.615257","exception":false,"start_time":"2023-03-22T22:47:48.024624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:45:58.201992Z","iopub.execute_input":"2023-09-12T15:45:58.202415Z","iopub.status.idle":"2023-09-12T15:46:17.650811Z","shell.execute_reply.started":"2023-09-12T15:45:58.202379Z","shell.execute_reply":"2023-09-12T15:46:17.649814Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class GatherLayer(tf.keras.layers.Layer):\n    def __init__(self, indices, **kwargs):\n        super(GatherLayer, self).__init__(**kwargs)\n        self.indices = indices\n        \n    def call(self, inputs):\n        return tf.gather(inputs, tf.cast(self.indices, dtype=tf.int32), axis=1)\n\nclass ChooseHand(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        \n    def call(self, inputs):\n        hand_inputs_final = []\n        for s in range(inputs.shape[0]):\n            left_hand_inputs = inputs[s, 1404:1467]\n            right_hand_inputs = inputs[s, 1566:1629]\n            hand_inputs = tf.cond(tf.equal(tf.reduce_sum(tf.abs(left_hand_inputs)), 0),\n                              lambda: right_hand_inputs,\n                              lambda: left_hand_inputs)\n            hand_inputs_final.append(hand_inputs)\n        stacked_hand_inputs = tf.stack(hand_inputs_final, axis=-1)\n        transposed_hand_inputs = tf.transpose(stacked_hand_inputs, perm=[1, 0])\n        return transposed_hand_inputs\n    \nclass HandKineticLayer(tf.keras.layers.Layer):\n    \n    def __init__(self, **kwargs):\n        super().__init__()\n    \n    def call(self, tensor):\n        end_ldmrk = [4*3,8*3,12*3,16*3, 19*3]\n        for index in range(0, 60, 3):\n            start = (index+3) if index in end_ldmrk else (index+6)\n        \n            dist_list = []\n            for x in range(start, 63, 3):\n                dx = tensor[:,index] - tensor[:,x]\n                dy = tensor[:,index+1] - tensor[:,x+1]\n                dist = tf.sqrt(tf.square(dx) + tf.square(dy))\n                dist_list.append(dist)\n                \n            dist_tensor = tf.stack(dist_list, axis=-1)\n            tensor = tf.concat([tensor, dist_tensor], axis=-1)\n        return tensor\n    \n    \nclass FaceKineticLayer(tf.keras.layers.Layer):\n    \n    def __init__(self, **kwargs):\n        super().__init__()\n    \n    def call(self, tensor):\n        for index in range(0, 36, 2):\n            start = (index+4)\n            \n            dist_list = []\n            for x in range(start, 40, 2):\n                dx = tensor[:,index] - tensor[:,x]\n                dy = tensor[:,index+1] - tensor[:,x+1]\n                dist = tf.sqrt(tf.square(dx) + tf.square(dy))\n                dist_list.append(dist)\n            \n            dist_tensor = tf.stack(dist_list, axis=-1)\n            tensor = tf.concat([tensor, dist_tensor], axis=-1)\n        return tensor\n\n    \nclass AngularLayer(tf.keras.layers.Layer):\n    \n    def __init__(self, **kwargs):\n        super().__init__()\n    \n    def call(self, tensor):\n        for index in range(0, 60, 3):\n            start = (index+3) \n            angle_list = []\n            for j in range(start, 63, 3):\n                vector = tensor[:, j:j+2] - tensor[:, index:index+2] \n                norms = tf.norm(vector, axis=1)\n                x_tilt = (tf.clip_by_value(vector[:, 0]/norms, -1.0, 1.0))\n                y_tilt = (tf.clip_by_value(vector[:, 1]/norms, -1.0, 1.0))\n                angle = tf.stack([x_tilt, y_tilt], axis=1)\n                angle_list.append(angle)\n            angle_tensor = tf.concat(angle_list, axis=-1)\n            tensor = tf.concat([tensor, angle_tensor], axis=-1)\n            tensor = tf.cast(tensor, tf.float32)\n        return tensor\n    \nclass FaceHandDistance(tf.keras.layers.Layer):\n    \n    def __init__(self, **kwargs):\n        super().__init__()\n    \n    def call(self, tensor):\n        start = 657\n        for index in range(0, 42, 2):\n            dist_list = []\n            for x in range(start, 697, 2):\n                dx = tensor[:,index] - tensor[:,x]\n                dy = tensor[:,index+1] - tensor[:,x+1]\n                dist = tf.sqrt(tf.square(dx) + tf.square(dy))\n                dist_list.append(dist)\n                \n            dist_tensor = tf.stack(dist_list, axis=-1)\n            tensor = tf.concat([tensor, dist_tensor], axis=-1)\n        return tensor","metadata":{"papermill":{"duration":0.050101,"end_time":"2023-03-22T22:48:08.680065","exception":false,"start_time":"2023-03-22T22:48:08.629964","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:46:21.531875Z","iopub.execute_input":"2023-09-12T15:46:21.532227Z","iopub.status.idle":"2023-09-12T15:46:21.560692Z","shell.execute_reply.started":"2023-09-12T15:46:21.532197Z","shell.execute_reply":"2023-09-12T15:46:21.559680Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"output_bias = tf.keras.initializers.Constant(1.0 / 250.0)\ndef ResidualBlock(inputs, nn, dropout):\n    x = tf.keras.layers.Dense(nn)(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Activation(\"gelu\")(x)\n    x = tf.keras.layers.Dropout(dropout)(x)\n    return x\n\ndef GRU(inputs, nn, dropout):\n    x = tf.keras.layers.GRU(nn, dropout=0.0, return_sequences=True)(inputs)\n    x = tf.keras.layers.GRU(nn, dropout=dropout, return_sequences=False)(inputs)\n    return x\n\nclass MSD(tf.keras.layers.Layer):\n    def __init__(self,units,**kwargs,):\n        super().__init__(**kwargs)\n\n        self.lin = tf.keras.layers.Dense(\n            units,\n            activation=None,\n            use_bias=True,\n            bias_initializer=output_bias,\n        )\n\n        self.dropouts = [tf.keras.layers.Dropout((0.5 - 0.2), seed=135 ),\n                tf.keras.layers.Dropout((0.5 - 0.1), seed=690 ),\n                tf.keras.layers.Dropout((0.5), seed=275 ),\n                tf.keras.layers.Dropout((0.5 + 0.1), seed=348 ),\n                tf.keras.layers.Dropout((0.5 + 0.2), seed=861),]\n\n    def call(self, inputs):\n        for ii, drop in enumerate(self.dropouts):\n            if ii == 0:\n                out = self.lin(drop(inputs)) / 5.0\n            else:\n                out += self.lin(drop(inputs)) / 5.0\n        return out","metadata":{"papermill":{"duration":0.032504,"end_time":"2023-03-22T22:48:08.727530","exception":false,"start_time":"2023-03-22T22:48:08.695026","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:47:48.010371Z","iopub.execute_input":"2023-09-12T15:47:48.010734Z","iopub.status.idle":"2023-09-12T15:47:48.022346Z","shell.execute_reply.started":"2023-09-12T15:47:48.010705Z","shell.execute_reply":"2023-09-12T15:47:48.021194Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    inputs = tf.keras.Input(batch_shape=(CFG.batch_size,) + (3258,), dtype=tf.float32)\n    hand_inputs = ChooseHand()(inputs) \n    hand_inputs = HandKineticLayer()(hand_inputs)  \n    hand_inputs = AngularLayer()(hand_inputs)\n    hand_coord = hand_inputs[:, :42]\n    hand_features = hand_inputs[:, 63:]\n    hand_inputs = tf.keras.layers.Concatenate(axis=1)([hand_coord, hand_features])\n    \n    lower_lip_indices = [78*3, 191*3, 80*3, 81*3, 82*3, 13*3, 312*3, 311*3, 310*3, 415*3,\n            95*3, 88*3, 178*3, 87*3, 14*3, 317*3, 402*3, 318*3, 324*3, 308*3,\n            78*3+1, 191*3+1, 80*3+1, 81*3+1, 82*3+1, 13*3+1, 312*3+1, 311*3+1, 310*3+1, 415*3+1,\n            95*3+1, 88*3+1, 178*3+1, 87*3+1, 14*3+1, 317*3+1, 402*3+1, 318*3+1, 324*3+1, 308*3+1]\n    \n    upper_lip_indices = [61*3, 185*3, 40*3, 39*3, 37*3, 0, 267*3, 269*3, 270*3, 409*3,\n            291*3, 146*3, 91*3, 181*3, 84*3, 17*3, 314*3, 405*3, 321*3, 375*3,\n            61*3+1, 185*3+1, 40*3+1, 39*3+1, 37*3+1, 0+1, 267*3+1, 269*3+1, 270*3+1, 409*3+1,\n            291*3+1, 146*3+1, 91*3+1, 181*3+1, 84*3+1, 17*3+1, 314*3+1, 405*3+1, 321*3+1, 375*3+1]\n    \n    lower_lip_inputs = GatherLayer(lower_lip_indices)(inputs)\n    lower_lip_inputs = FaceKineticLayer()(lower_lip_inputs)\n    \n    upper_lip_inputs = GatherLayer(upper_lip_indices)(inputs)\n    upper_lip_inputs = FaceKineticLayer()(upper_lip_inputs)\n    \n    upper_body_indices = [16*3, 14*3, 12*3, 11*3, 13*3, 15*3,\n                          16*3+1, 14*3+1, 12*3+1, 11*3+1, 13*3+1, 15*3+1]\n    pose_inputs = GatherLayer(upper_body_indices)(inputs)\n    \n    all_inputs = tf.keras.layers.Concatenate(axis=1)([hand_inputs, lower_lip_inputs, upper_lip_inputs, pose_inputs])\n#     all_inputs = FaceHandDistance()(all_inputs)\n    \n    all_conv = tf.reshape(all_inputs, (-1, 1, all_inputs.shape[1]))\n    \n    vector = GRU(all_conv, 1024//2, 0.5)     \n    vector = ResidualBlock(vector, 1024//1, 0.25)     \n    vector = ResidualBlock(vector, 1024//1, 0.0)\n    vector = MSD(1024//4)(vector)\n    \n    vector = tf.keras.layers.Flatten()(vector)\n    output = tf.keras.layers.Dense(250, activation=\"softmax\")(vector)\n    model = tf.keras.Model(inputs=inputs, outputs=output)\n    model.compile(tf.keras.optimizers.Adam(0.000333), \"sparse_categorical_crossentropy\", \n                  metrics =[\"sparse_top_k_categorical_accuracy\", \"acc\"])\n    return model","metadata":{"papermill":{"duration":0.040339,"end_time":"2023-03-22T22:48:08.782373","exception":false,"start_time":"2023-03-22T22:48:08.742034","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:47:49.836626Z","iopub.execute_input":"2023-09-12T15:47:49.836971Z","iopub.status.idle":"2023-09-12T15:47:49.856617Z","shell.execute_reply.started":"2023-09-12T15:47:49.836943Z","shell.execute_reply":"2023-09-12T15:47:49.855509Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Model 1","metadata":{"papermill":{"duration":0.014641,"end_time":"2023-03-22T22:48:08.813156","exception":false,"start_time":"2023-03-22T22:48:08.798515","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import keras.backend as K\n\nK.clear_session()\nmodel1 = build_model()\nmodel1.summary()\n# tf.keras.utils.plot_model(model1)","metadata":{"papermill":{"duration":21.467709,"end_time":"2023-03-22T22:48:30.295809","exception":false,"start_time":"2023-03-22T22:48:08.828100","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:47:54.475726Z","iopub.execute_input":"2023-09-12T15:47:54.476072Z","iopub.status.idle":"2023-09-12T15:48:15.250634Z","shell.execute_reply.started":"2023-09-12T15:47:54.476043Z","shell.execute_reply":"2023-09-12T15:48:15.249706Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(512, 3258)]        0           []                               \n                                                                                                  \n choose_hand (ChooseHand)       (512, 63)            0           ['input_1[0][0]']                \n                                                                                                  \n hand_kinetic_layer (HandKineti  (512, 258)          0           ['choose_hand[0][0]']            \n cLayer)                                                                                          \n                                                                                                  \n angular_layer (AngularLayer)   (512, 678)           0           ['hand_kinetic_layer[0][0]']     \n                                                                                                  \n tf.__operators__.getitem (Slic  (512, 42)           0           ['angular_layer[0][0]']          \n ingOpLambda)                                                                                     \n                                                                                                  \n tf.__operators__.getitem_1 (Sl  (512, 615)          0           ['angular_layer[0][0]']          \n icingOpLambda)                                                                                   \n                                                                                                  \n gather_layer (GatherLayer)     (512, 40)            0           ['input_1[0][0]']                \n                                                                                                  \n gather_layer_1 (GatherLayer)   (512, 40)            0           ['input_1[0][0]']                \n                                                                                                  \n concatenate (Concatenate)      (512, 657)           0           ['tf.__operators__.getitem[0][0]'\n                                                                 , 'tf.__operators__.getitem_1[0][\n                                                                 0]']                             \n                                                                                                  \n face_kinetic_layer (FaceKineti  (512, 211)          0           ['gather_layer[0][0]']           \n cLayer)                                                                                          \n                                                                                                  \n face_kinetic_layer_1 (FaceKine  (512, 211)          0           ['gather_layer_1[0][0]']         \n ticLayer)                                                                                        \n                                                                                                  \n gather_layer_2 (GatherLayer)   (512, 12)            0           ['input_1[0][0]']                \n                                                                                                  \n concatenate_1 (Concatenate)    (512, 1091)          0           ['concatenate[0][0]',            \n                                                                  'face_kinetic_layer[0][0]',     \n                                                                  'face_kinetic_layer_1[0][0]',   \n                                                                  'gather_layer_2[0][0]']         \n                                                                                                  \n tf.reshape (TFOpLambda)        (512, 1, 1091)       0           ['concatenate_1[0][0]']          \n                                                                                                  \n gru_1 (GRU)                    (512, 512)           2465280     ['tf.reshape[0][0]']             \n                                                                                                  \n dense (Dense)                  (512, 1024)          525312      ['gru_1[0][0]']                  \n                                                                                                  \n batch_normalization (BatchNorm  (512, 1024)         4096        ['dense[0][0]']                  \n alization)                                                                                       \n                                                                                                  \n activation (Activation)        (512, 1024)          0           ['batch_normalization[0][0]']    \n                                                                                                  \n dropout (Dropout)              (512, 1024)          0           ['activation[0][0]']             \n                                                                                                  \n dense_1 (Dense)                (512, 1024)          1049600     ['dropout[0][0]']                \n                                                                                                  \n batch_normalization_1 (BatchNo  (512, 1024)         4096        ['dense_1[0][0]']                \n rmalization)                                                                                     \n                                                                                                  \n activation_1 (Activation)      (512, 1024)          0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n dropout_1 (Dropout)            (512, 1024)          0           ['activation_1[0][0]']           \n                                                                                                  \n msd (MSD)                      (512, 256)           262400      ['dropout_1[0][0]']              \n                                                                                                  \n flatten (Flatten)              (512, 256)           0           ['msd[0][0]']                    \n                                                                                                  \n dense_3 (Dense)                (512, 250)           64250       ['flatten[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 4,375,034\nTrainable params: 4,370,938\nNon-trainable params: 4,096\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train Model","metadata":{"papermill":{"duration":0.022232,"end_time":"2023-03-22T22:48:30.341564","exception":false,"start_time":"2023-03-22T22:48:30.319332","status":"completed"},"tags":[]}},{"cell_type":"code","source":"file_name = \"model1\"\ncallbacks = [\n        tf.keras.callbacks.ModelCheckpoint(\n            file_name, \n            save_best_only=True, \n            restore_best_weights=True, \n            monitor=\"val_accuracy\",\n            mode=\"max\"\n        ),\n        tf.keras.callbacks.EarlyStopping(\n            monitor=\"val_accuracy\",\n            mode=\"max\",\n            patience=5\n        ),\n        tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.8, verbose=1)\n    ]\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\ntrain_dataset = train_dataset.batch(batch_size=CFG.batch_size, drop_remainder=True)\nval_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\nval_dataset = val_dataset.batch(batch_size=CFG.batch_size, drop_remainder=True)","metadata":{"papermill":{"duration":4927.345525,"end_time":"2023-03-23T00:10:37.709304","exception":false,"start_time":"2023-03-22T22:48:30.363779","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-12T15:49:10.474278Z","iopub.execute_input":"2023-09-12T15:49:10.474643Z","iopub.status.idle":"2023-09-12T15:49:12.737280Z","shell.execute_reply.started":"2023-09-12T15:49:10.474613Z","shell.execute_reply":"2023-09-12T15:49:12.736272Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\nmodel1.fit(train_dataset, epochs=100, validation_data=val_dataset, batch_size=CFG.batch_size, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T15:52:36.583072Z","iopub.execute_input":"2023-09-12T15:52:36.583435Z","iopub.status.idle":"2023-09-12T16:35:50.356144Z","shell.execute_reply.started":"2023-09-12T15:52:36.583404Z","shell.execute_reply":"2023-09-12T16:35:50.355157Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/100\n166/166 [==============================] - 114s 324ms/step - loss: 4.4769 - sparse_top_k_categorical_accuracy: 0.2593 - acc: 0.0902 - val_loss: 3.8043 - val_sparse_top_k_categorical_accuracy: 0.4800 - val_acc: 0.2041 - lr: 3.3300e-04\nEpoch 2/100\n166/166 [==============================] - 22s 131ms/step - loss: 3.5319 - sparse_top_k_categorical_accuracy: 0.4736 - acc: 0.1974 - val_loss: 3.0336 - val_sparse_top_k_categorical_accuracy: 0.5907 - val_acc: 0.2847 - lr: 3.3300e-04\nEpoch 3/100\n166/166 [==============================] - 22s 133ms/step - loss: 3.2167 - sparse_top_k_categorical_accuracy: 0.5482 - acc: 0.2475 - val_loss: 2.7781 - val_sparse_top_k_categorical_accuracy: 0.6476 - val_acc: 0.3365 - lr: 3.3300e-04\nEpoch 4/100\n166/166 [==============================] - 22s 131ms/step - loss: 3.0347 - sparse_top_k_categorical_accuracy: 0.5898 - acc: 0.2808 - val_loss: 2.6287 - val_sparse_top_k_categorical_accuracy: 0.6759 - val_acc: 0.3681 - lr: 3.3300e-04\nEpoch 5/100\n166/166 [==============================] - 21s 128ms/step - loss: 2.9097 - sparse_top_k_categorical_accuracy: 0.6167 - acc: 0.3037 - val_loss: 2.5281 - val_sparse_top_k_categorical_accuracy: 0.6973 - val_acc: 0.3900 - lr: 3.3300e-04\nEpoch 6/100\n166/166 [==============================] - 22s 135ms/step - loss: 2.8103 - sparse_top_k_categorical_accuracy: 0.6379 - acc: 0.3196 - val_loss: 2.4458 - val_sparse_top_k_categorical_accuracy: 0.7138 - val_acc: 0.4027 - lr: 3.3300e-04\nEpoch 7/100\n166/166 [==============================] - 22s 130ms/step - loss: 2.7361 - sparse_top_k_categorical_accuracy: 0.6516 - acc: 0.3343 - val_loss: 2.3681 - val_sparse_top_k_categorical_accuracy: 0.7260 - val_acc: 0.4246 - lr: 3.3300e-04\nEpoch 8/100\n166/166 [==============================] - 22s 134ms/step - loss: 2.6633 - sparse_top_k_categorical_accuracy: 0.6660 - acc: 0.3491 - val_loss: 2.3200 - val_sparse_top_k_categorical_accuracy: 0.7308 - val_acc: 0.4367 - lr: 3.3300e-04\nEpoch 9/100\n166/166 [==============================] - 23s 136ms/step - loss: 2.6094 - sparse_top_k_categorical_accuracy: 0.6786 - acc: 0.3592 - val_loss: 2.2829 - val_sparse_top_k_categorical_accuracy: 0.7398 - val_acc: 0.4429 - lr: 3.3300e-04\nEpoch 10/100\n166/166 [==============================] - 21s 129ms/step - loss: 2.5641 - sparse_top_k_categorical_accuracy: 0.6857 - acc: 0.3685 - val_loss: 2.2271 - val_sparse_top_k_categorical_accuracy: 0.7480 - val_acc: 0.4580 - lr: 3.3300e-04\nEpoch 11/100\n166/166 [==============================] - 22s 134ms/step - loss: 2.5192 - sparse_top_k_categorical_accuracy: 0.6953 - acc: 0.3764 - val_loss: 2.2001 - val_sparse_top_k_categorical_accuracy: 0.7550 - val_acc: 0.4607 - lr: 3.3300e-04\nEpoch 12/100\n166/166 [==============================] - 21s 129ms/step - loss: 2.4715 - sparse_top_k_categorical_accuracy: 0.7040 - acc: 0.3875 - val_loss: 2.1566 - val_sparse_top_k_categorical_accuracy: 0.7606 - val_acc: 0.4702 - lr: 3.3300e-04\nEpoch 13/100\n166/166 [==============================] - 22s 132ms/step - loss: 2.4365 - sparse_top_k_categorical_accuracy: 0.7096 - acc: 0.3925 - val_loss: 2.1212 - val_sparse_top_k_categorical_accuracy: 0.7692 - val_acc: 0.4771 - lr: 3.3300e-04\nEpoch 14/100\n166/166 [==============================] - 21s 128ms/step - loss: 2.3976 - sparse_top_k_categorical_accuracy: 0.7175 - acc: 0.4000 - val_loss: 2.1011 - val_sparse_top_k_categorical_accuracy: 0.7702 - val_acc: 0.4826 - lr: 3.3300e-04\nEpoch 15/100\n166/166 [==============================] - 22s 132ms/step - loss: 2.3599 - sparse_top_k_categorical_accuracy: 0.7249 - acc: 0.4072 - val_loss: 2.0723 - val_sparse_top_k_categorical_accuracy: 0.7724 - val_acc: 0.4920 - lr: 3.3300e-04\nEpoch 16/100\n166/166 [==============================] - 22s 134ms/step - loss: 2.3368 - sparse_top_k_categorical_accuracy: 0.7282 - acc: 0.4127 - val_loss: 2.0448 - val_sparse_top_k_categorical_accuracy: 0.7770 - val_acc: 0.5013 - lr: 3.3300e-04\nEpoch 17/100\n166/166 [==============================] - 21s 128ms/step - loss: 2.3011 - sparse_top_k_categorical_accuracy: 0.7351 - acc: 0.4181 - val_loss: 2.0281 - val_sparse_top_k_categorical_accuracy: 0.7807 - val_acc: 0.5022 - lr: 3.3300e-04\nEpoch 18/100\n166/166 [==============================] - 22s 131ms/step - loss: 2.2723 - sparse_top_k_categorical_accuracy: 0.7389 - acc: 0.4260 - val_loss: 2.0080 - val_sparse_top_k_categorical_accuracy: 0.7811 - val_acc: 0.5059 - lr: 3.3300e-04\nEpoch 19/100\n166/166 [==============================] - 21s 128ms/step - loss: 2.2452 - sparse_top_k_categorical_accuracy: 0.7450 - acc: 0.4311 - val_loss: 1.9877 - val_sparse_top_k_categorical_accuracy: 0.7844 - val_acc: 0.5105 - lr: 3.3300e-04\nEpoch 20/100\n166/166 [==============================] - 22s 132ms/step - loss: 2.2167 - sparse_top_k_categorical_accuracy: 0.7481 - acc: 0.4367 - val_loss: 1.9828 - val_sparse_top_k_categorical_accuracy: 0.7861 - val_acc: 0.5118 - lr: 3.3300e-04\nEpoch 21/100\n166/166 [==============================] - 22s 132ms/step - loss: 2.1942 - sparse_top_k_categorical_accuracy: 0.7531 - acc: 0.4429 - val_loss: 1.9688 - val_sparse_top_k_categorical_accuracy: 0.7870 - val_acc: 0.5180 - lr: 3.3300e-04\nEpoch 22/100\n166/166 [==============================] - 21s 129ms/step - loss: 2.1699 - sparse_top_k_categorical_accuracy: 0.7565 - acc: 0.4465 - val_loss: 1.9432 - val_sparse_top_k_categorical_accuracy: 0.7930 - val_acc: 0.5209 - lr: 3.3300e-04\nEpoch 23/100\n166/166 [==============================] - 23s 136ms/step - loss: 2.1449 - sparse_top_k_categorical_accuracy: 0.7607 - acc: 0.4487 - val_loss: 1.9341 - val_sparse_top_k_categorical_accuracy: 0.7938 - val_acc: 0.5246 - lr: 3.3300e-04\nEpoch 24/100\n166/166 [==============================] - 22s 134ms/step - loss: 2.1226 - sparse_top_k_categorical_accuracy: 0.7638 - acc: 0.4551 - val_loss: 1.9165 - val_sparse_top_k_categorical_accuracy: 0.7950 - val_acc: 0.5289 - lr: 3.3300e-04\nEpoch 25/100\n166/166 [==============================] - 22s 132ms/step - loss: 2.1022 - sparse_top_k_categorical_accuracy: 0.7675 - acc: 0.4593 - val_loss: 1.9051 - val_sparse_top_k_categorical_accuracy: 0.7959 - val_acc: 0.5365 - lr: 3.3300e-04\nEpoch 26/100\n166/166 [==============================] - 22s 133ms/step - loss: 2.0756 - sparse_top_k_categorical_accuracy: 0.7708 - acc: 0.4641 - val_loss: 1.8982 - val_sparse_top_k_categorical_accuracy: 0.7985 - val_acc: 0.5363 - lr: 3.3300e-04\nEpoch 27/100\n166/166 [==============================] - 22s 131ms/step - loss: 2.0592 - sparse_top_k_categorical_accuracy: 0.7756 - acc: 0.4674 - val_loss: 1.8866 - val_sparse_top_k_categorical_accuracy: 0.8014 - val_acc: 0.5377 - lr: 3.3300e-04\nEpoch 28/100\n166/166 [==============================] - 21s 128ms/step - loss: 2.0372 - sparse_top_k_categorical_accuracy: 0.7784 - acc: 0.4737 - val_loss: 1.8750 - val_sparse_top_k_categorical_accuracy: 0.8007 - val_acc: 0.5416 - lr: 3.3300e-04\nEpoch 29/100\n166/166 [==============================] - 22s 130ms/step - loss: 2.0202 - sparse_top_k_categorical_accuracy: 0.7805 - acc: 0.4753 - val_loss: 1.8674 - val_sparse_top_k_categorical_accuracy: 0.8058 - val_acc: 0.5383 - lr: 3.3300e-04\nEpoch 30/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.9989 - sparse_top_k_categorical_accuracy: 0.7849 - acc: 0.4803 - val_loss: 1.8633 - val_sparse_top_k_categorical_accuracy: 0.8061 - val_acc: 0.5447 - lr: 3.3300e-04\nEpoch 31/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.9798 - sparse_top_k_categorical_accuracy: 0.7869 - acc: 0.4836 - val_loss: 1.8569 - val_sparse_top_k_categorical_accuracy: 0.8059 - val_acc: 0.5455 - lr: 3.3300e-04\nEpoch 32/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.9658 - sparse_top_k_categorical_accuracy: 0.7888 - acc: 0.4871 - val_loss: 1.8458 - val_sparse_top_k_categorical_accuracy: 0.8064 - val_acc: 0.5484 - lr: 3.3300e-04\nEpoch 33/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.9447 - sparse_top_k_categorical_accuracy: 0.7933 - acc: 0.4910 - val_loss: 1.8381 - val_sparse_top_k_categorical_accuracy: 0.8062 - val_acc: 0.5503 - lr: 3.3300e-04\nEpoch 34/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.9290 - sparse_top_k_categorical_accuracy: 0.7952 - acc: 0.4919 - val_loss: 1.8247 - val_sparse_top_k_categorical_accuracy: 0.8111 - val_acc: 0.5543 - lr: 3.3300e-04\nEpoch 35/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.9081 - sparse_top_k_categorical_accuracy: 0.7995 - acc: 0.4990 - val_loss: 1.8219 - val_sparse_top_k_categorical_accuracy: 0.8071 - val_acc: 0.5566 - lr: 3.3300e-04\nEpoch 36/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.8935 - sparse_top_k_categorical_accuracy: 0.8018 - acc: 0.5009 - val_loss: 1.8256 - val_sparse_top_k_categorical_accuracy: 0.8109 - val_acc: 0.5533 - lr: 3.3300e-04\nEpoch 37/100\n166/166 [==============================] - 22s 130ms/step - loss: 1.8827 - sparse_top_k_categorical_accuracy: 0.8027 - acc: 0.5035 - val_loss: 1.8068 - val_sparse_top_k_categorical_accuracy: 0.8133 - val_acc: 0.5572 - lr: 3.3300e-04\nEpoch 38/100\n166/166 [==============================] - 21s 130ms/step - loss: 1.8586 - sparse_top_k_categorical_accuracy: 0.8073 - acc: 0.5084 - val_loss: 1.8063 - val_sparse_top_k_categorical_accuracy: 0.8129 - val_acc: 0.5621 - lr: 3.3300e-04\nEpoch 39/100\n166/166 [==============================] - 23s 136ms/step - loss: 1.8522 - sparse_top_k_categorical_accuracy: 0.8079 - acc: 0.5097 - val_loss: 1.8099 - val_sparse_top_k_categorical_accuracy: 0.8122 - val_acc: 0.5614 - lr: 3.3300e-04\nEpoch 40/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.8310 - sparse_top_k_categorical_accuracy: 0.8113 - acc: 0.5142 - val_loss: 1.8025 - val_sparse_top_k_categorical_accuracy: 0.8121 - val_acc: 0.5647 - lr: 3.3300e-04\nEpoch 41/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.8213 - sparse_top_k_categorical_accuracy: 0.8126 - acc: 0.5171 - val_loss: 1.8067 - val_sparse_top_k_categorical_accuracy: 0.8114 - val_acc: 0.5623 - lr: 3.3300e-04\nEpoch 42/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.7960 - sparse_top_k_categorical_accuracy: 0.8170 - acc: 0.5215 - val_loss: 1.7925 - val_sparse_top_k_categorical_accuracy: 0.8147 - val_acc: 0.5639 - lr: 3.3300e-04\nEpoch 43/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.7907 - sparse_top_k_categorical_accuracy: 0.8191 - acc: 0.5214 - val_loss: 1.7916 - val_sparse_top_k_categorical_accuracy: 0.8176 - val_acc: 0.5674 - lr: 3.3300e-04\nEpoch 44/100\n166/166 [==============================] - 22s 130ms/step - loss: 1.7693 - sparse_top_k_categorical_accuracy: 0.8217 - acc: 0.5257 - val_loss: 1.7878 - val_sparse_top_k_categorical_accuracy: 0.8161 - val_acc: 0.5685 - lr: 3.3300e-04\nEpoch 45/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.7549 - sparse_top_k_categorical_accuracy: 0.8243 - acc: 0.5279 - val_loss: 1.7856 - val_sparse_top_k_categorical_accuracy: 0.8177 - val_acc: 0.5678 - lr: 3.3300e-04\nEpoch 46/100\n166/166 [==============================] - 21s 126ms/step - loss: 1.7418 - sparse_top_k_categorical_accuracy: 0.8253 - acc: 0.5323 - val_loss: 1.7739 - val_sparse_top_k_categorical_accuracy: 0.8152 - val_acc: 0.5771 - lr: 3.3300e-04\nEpoch 47/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.7256 - sparse_top_k_categorical_accuracy: 0.8277 - acc: 0.5341 - val_loss: 1.7801 - val_sparse_top_k_categorical_accuracy: 0.8187 - val_acc: 0.5719 - lr: 3.3300e-04\nEpoch 48/100\n166/166 [==============================] - ETA: 0s - loss: 1.7134 - sparse_top_k_categorical_accuracy: 0.8295 - acc: 0.5383\nEpoch 48: ReduceLROnPlateau reducing learning rate to 0.000266400002874434.\n166/166 [==============================] - 22s 132ms/step - loss: 1.7134 - sparse_top_k_categorical_accuracy: 0.8295 - acc: 0.5383 - val_loss: 1.7764 - val_sparse_top_k_categorical_accuracy: 0.8169 - val_acc: 0.5741 - lr: 3.3300e-04\nEpoch 49/100\n166/166 [==============================] - 21s 127ms/step - loss: 1.6878 - sparse_top_k_categorical_accuracy: 0.8335 - acc: 0.5439 - val_loss: 1.7674 - val_sparse_top_k_categorical_accuracy: 0.8196 - val_acc: 0.5769 - lr: 2.6640e-04\nEpoch 50/100\n166/166 [==============================] - 22s 130ms/step - loss: 1.6631 - sparse_top_k_categorical_accuracy: 0.8382 - acc: 0.5488 - val_loss: 1.7609 - val_sparse_top_k_categorical_accuracy: 0.8196 - val_acc: 0.5794 - lr: 2.6640e-04\nEpoch 51/100\n166/166 [==============================] - 22s 133ms/step - loss: 1.6514 - sparse_top_k_categorical_accuracy: 0.8403 - acc: 0.5509 - val_loss: 1.7650 - val_sparse_top_k_categorical_accuracy: 0.8169 - val_acc: 0.5791 - lr: 2.6640e-04\nEpoch 52/100\n166/166 [==============================] - 22s 134ms/step - loss: 1.6456 - sparse_top_k_categorical_accuracy: 0.8398 - acc: 0.5520 - val_loss: 1.7579 - val_sparse_top_k_categorical_accuracy: 0.8187 - val_acc: 0.5788 - lr: 2.6640e-04\nEpoch 53/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.6259 - sparse_top_k_categorical_accuracy: 0.8429 - acc: 0.5572 - val_loss: 1.7610 - val_sparse_top_k_categorical_accuracy: 0.8190 - val_acc: 0.5812 - lr: 2.6640e-04\nEpoch 54/100\n166/166 [==============================] - 22s 134ms/step - loss: 1.6227 - sparse_top_k_categorical_accuracy: 0.8463 - acc: 0.5563 - val_loss: 1.7526 - val_sparse_top_k_categorical_accuracy: 0.8205 - val_acc: 0.5821 - lr: 2.6640e-04\nEpoch 55/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.6056 - sparse_top_k_categorical_accuracy: 0.8470 - acc: 0.5622 - val_loss: 1.7601 - val_sparse_top_k_categorical_accuracy: 0.8220 - val_acc: 0.5763 - lr: 2.6640e-04\nEpoch 56/100\n166/166 [==============================] - ETA: 0s - loss: 1.5971 - sparse_top_k_categorical_accuracy: 0.8477 - acc: 0.5625\nEpoch 56: ReduceLROnPlateau reducing learning rate to 0.00021311999298632145.\n166/166 [==============================] - 22s 135ms/step - loss: 1.5971 - sparse_top_k_categorical_accuracy: 0.8477 - acc: 0.5625 - val_loss: 1.7635 - val_sparse_top_k_categorical_accuracy: 0.8201 - val_acc: 0.5786 - lr: 2.6640e-04\nEpoch 57/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.5753 - sparse_top_k_categorical_accuracy: 0.8521 - acc: 0.5663 - val_loss: 1.7483 - val_sparse_top_k_categorical_accuracy: 0.8229 - val_acc: 0.5846 - lr: 2.1312e-04\nEpoch 58/100\n166/166 [==============================] - 22s 130ms/step - loss: 1.5564 - sparse_top_k_categorical_accuracy: 0.8547 - acc: 0.5731 - val_loss: 1.7461 - val_sparse_top_k_categorical_accuracy: 0.8219 - val_acc: 0.5841 - lr: 2.1312e-04\nEpoch 59/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.5505 - sparse_top_k_categorical_accuracy: 0.8556 - acc: 0.5718 - val_loss: 1.7483 - val_sparse_top_k_categorical_accuracy: 0.8213 - val_acc: 0.5890 - lr: 2.1312e-04\nEpoch 60/100\n166/166 [==============================] - ETA: 0s - loss: 1.5316 - sparse_top_k_categorical_accuracy: 0.8580 - acc: 0.5771\nEpoch 60: ReduceLROnPlateau reducing learning rate to 0.0001704959897324443.\n166/166 [==============================] - 22s 130ms/step - loss: 1.5316 - sparse_top_k_categorical_accuracy: 0.8580 - acc: 0.5771 - val_loss: 1.7546 - val_sparse_top_k_categorical_accuracy: 0.8191 - val_acc: 0.5877 - lr: 2.1312e-04\nEpoch 61/100\n166/166 [==============================] - 21s 126ms/step - loss: 1.5139 - sparse_top_k_categorical_accuracy: 0.8606 - acc: 0.5818 - val_loss: 1.7372 - val_sparse_top_k_categorical_accuracy: 0.8240 - val_acc: 0.5922 - lr: 1.7050e-04\nEpoch 62/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.5072 - sparse_top_k_categorical_accuracy: 0.8620 - acc: 0.5823 - val_loss: 1.7354 - val_sparse_top_k_categorical_accuracy: 0.8230 - val_acc: 0.5917 - lr: 1.7050e-04\nEpoch 63/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.4942 - sparse_top_k_categorical_accuracy: 0.8634 - acc: 0.5855 - val_loss: 1.7362 - val_sparse_top_k_categorical_accuracy: 0.8232 - val_acc: 0.5922 - lr: 1.7050e-04\nEpoch 64/100\n166/166 [==============================] - ETA: 0s - loss: 1.4849 - sparse_top_k_categorical_accuracy: 0.8654 - acc: 0.5882\nEpoch 64: ReduceLROnPlateau reducing learning rate to 0.000136396789457649.\n166/166 [==============================] - 22s 132ms/step - loss: 1.4849 - sparse_top_k_categorical_accuracy: 0.8654 - acc: 0.5882 - val_loss: 1.7374 - val_sparse_top_k_categorical_accuracy: 0.8235 - val_acc: 0.5909 - lr: 1.7050e-04\nEpoch 65/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.4701 - sparse_top_k_categorical_accuracy: 0.8677 - acc: 0.5915 - val_loss: 1.7342 - val_sparse_top_k_categorical_accuracy: 0.8228 - val_acc: 0.5918 - lr: 1.3640e-04\nEpoch 66/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.4573 - sparse_top_k_categorical_accuracy: 0.8693 - acc: 0.5935 - val_loss: 1.7337 - val_sparse_top_k_categorical_accuracy: 0.8249 - val_acc: 0.5924 - lr: 1.3640e-04\nEpoch 67/100\n166/166 [==============================] - 22s 133ms/step - loss: 1.4490 - sparse_top_k_categorical_accuracy: 0.8711 - acc: 0.5961 - val_loss: 1.7337 - val_sparse_top_k_categorical_accuracy: 0.8219 - val_acc: 0.5965 - lr: 1.3640e-04\nEpoch 68/100\n166/166 [==============================] - 22s 132ms/step - loss: 1.4420 - sparse_top_k_categorical_accuracy: 0.8717 - acc: 0.5962 - val_loss: 1.7321 - val_sparse_top_k_categorical_accuracy: 0.8250 - val_acc: 0.5955 - lr: 1.3640e-04\nEpoch 69/100\n166/166 [==============================] - 23s 138ms/step - loss: 1.4386 - sparse_top_k_categorical_accuracy: 0.8734 - acc: 0.5967 - val_loss: 1.7345 - val_sparse_top_k_categorical_accuracy: 0.8243 - val_acc: 0.5961 - lr: 1.3640e-04\nEpoch 70/100\n166/166 [==============================] - ETA: 0s - loss: 1.4302 - sparse_top_k_categorical_accuracy: 0.8722 - acc: 0.6024\nEpoch 70: ReduceLROnPlateau reducing learning rate to 0.0001091174315661192.\n166/166 [==============================] - 22s 132ms/step - loss: 1.4302 - sparse_top_k_categorical_accuracy: 0.8722 - acc: 0.6024 - val_loss: 1.7348 - val_sparse_top_k_categorical_accuracy: 0.8244 - val_acc: 0.5952 - lr: 1.3640e-04\nEpoch 71/100\n166/166 [==============================] - 23s 139ms/step - loss: 1.4162 - sparse_top_k_categorical_accuracy: 0.8753 - acc: 0.6017 - val_loss: 1.7327 - val_sparse_top_k_categorical_accuracy: 0.8237 - val_acc: 0.5955 - lr: 1.0912e-04\nEpoch 72/100\n166/166 [==============================] - 22s 134ms/step - loss: 1.4146 - sparse_top_k_categorical_accuracy: 0.8753 - acc: 0.6041 - val_loss: 1.7314 - val_sparse_top_k_categorical_accuracy: 0.8247 - val_acc: 0.5962 - lr: 1.0912e-04\nEpoch 73/100\n166/166 [==============================] - 21s 127ms/step - loss: 1.4095 - sparse_top_k_categorical_accuracy: 0.8760 - acc: 0.6047 - val_loss: 1.7298 - val_sparse_top_k_categorical_accuracy: 0.8250 - val_acc: 0.5944 - lr: 1.0912e-04\nEpoch 74/100\n166/166 [==============================] - 22s 134ms/step - loss: 1.4012 - sparse_top_k_categorical_accuracy: 0.8789 - acc: 0.6069 - val_loss: 1.7301 - val_sparse_top_k_categorical_accuracy: 0.8242 - val_acc: 0.6000 - lr: 1.0912e-04\nEpoch 75/100\n166/166 [==============================] - ETA: 0s - loss: 1.3935 - sparse_top_k_categorical_accuracy: 0.8784 - acc: 0.6075\nEpoch 75: ReduceLROnPlateau reducing learning rate to 8.72939475812018e-05.\n166/166 [==============================] - 22s 133ms/step - loss: 1.3935 - sparse_top_k_categorical_accuracy: 0.8784 - acc: 0.6075 - val_loss: 1.7312 - val_sparse_top_k_categorical_accuracy: 0.8255 - val_acc: 0.5973 - lr: 1.0912e-04\nEpoch 76/100\n166/166 [==============================] - 21s 126ms/step - loss: 1.3836 - sparse_top_k_categorical_accuracy: 0.8787 - acc: 0.6118 - val_loss: 1.7299 - val_sparse_top_k_categorical_accuracy: 0.8261 - val_acc: 0.5977 - lr: 8.7294e-05\nEpoch 77/100\n166/166 [==============================] - ETA: 0s - loss: 1.3769 - sparse_top_k_categorical_accuracy: 0.8793 - acc: 0.6137\nEpoch 77: ReduceLROnPlateau reducing learning rate to 6.983515922911466e-05.\n166/166 [==============================] - 22s 132ms/step - loss: 1.3769 - sparse_top_k_categorical_accuracy: 0.8793 - acc: 0.6137 - val_loss: 1.7324 - val_sparse_top_k_categorical_accuracy: 0.8251 - val_acc: 0.6017 - lr: 8.7294e-05\nEpoch 78/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.3663 - sparse_top_k_categorical_accuracy: 0.8825 - acc: 0.6160 - val_loss: 1.7292 - val_sparse_top_k_categorical_accuracy: 0.8261 - val_acc: 0.6019 - lr: 6.9835e-05\nEpoch 79/100\n166/166 [==============================] - 21s 126ms/step - loss: 1.3580 - sparse_top_k_categorical_accuracy: 0.8837 - acc: 0.6168 - val_loss: 1.7246 - val_sparse_top_k_categorical_accuracy: 0.8248 - val_acc: 0.6021 - lr: 6.9835e-05\nEpoch 80/100\n166/166 [==============================] - 22s 130ms/step - loss: 1.3531 - sparse_top_k_categorical_accuracy: 0.8847 - acc: 0.6180 - val_loss: 1.7298 - val_sparse_top_k_categorical_accuracy: 0.8262 - val_acc: 0.6006 - lr: 6.9835e-05\nEpoch 81/100\n166/166 [==============================] - ETA: 0s - loss: 1.3531 - sparse_top_k_categorical_accuracy: 0.8842 - acc: 0.6192\nEpoch 81: ReduceLROnPlateau reducing learning rate to 5.586812621913851e-05.\n166/166 [==============================] - 21s 128ms/step - loss: 1.3531 - sparse_top_k_categorical_accuracy: 0.8842 - acc: 0.6192 - val_loss: 1.7279 - val_sparse_top_k_categorical_accuracy: 0.8261 - val_acc: 0.6011 - lr: 6.9835e-05\nEpoch 82/100\n166/166 [==============================] - 21s 130ms/step - loss: 1.3451 - sparse_top_k_categorical_accuracy: 0.8845 - acc: 0.6195 - val_loss: 1.7234 - val_sparse_top_k_categorical_accuracy: 0.8276 - val_acc: 0.6035 - lr: 5.5868e-05\nEpoch 83/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.3393 - sparse_top_k_categorical_accuracy: 0.8865 - acc: 0.6208 - val_loss: 1.7266 - val_sparse_top_k_categorical_accuracy: 0.8270 - val_acc: 0.6005 - lr: 5.5868e-05\nEpoch 84/100\n166/166 [==============================] - ETA: 0s - loss: 1.3371 - sparse_top_k_categorical_accuracy: 0.8864 - acc: 0.6199\nEpoch 84: ReduceLROnPlateau reducing learning rate to 4.4694502139464025e-05.\n166/166 [==============================] - 21s 127ms/step - loss: 1.3371 - sparse_top_k_categorical_accuracy: 0.8864 - acc: 0.6199 - val_loss: 1.7287 - val_sparse_top_k_categorical_accuracy: 0.8253 - val_acc: 0.6055 - lr: 5.5868e-05\nEpoch 85/100\n166/166 [==============================] - 22s 133ms/step - loss: 1.3350 - sparse_top_k_categorical_accuracy: 0.8862 - acc: 0.6246 - val_loss: 1.7244 - val_sparse_top_k_categorical_accuracy: 0.8258 - val_acc: 0.6051 - lr: 4.4695e-05\nEpoch 86/100\n166/166 [==============================] - ETA: 0s - loss: 1.3242 - sparse_top_k_categorical_accuracy: 0.8875 - acc: 0.6258\nEpoch 86: ReduceLROnPlateau reducing learning rate to 3.575560112949461e-05.\n166/166 [==============================] - 22s 131ms/step - loss: 1.3242 - sparse_top_k_categorical_accuracy: 0.8875 - acc: 0.6258 - val_loss: 1.7277 - val_sparse_top_k_categorical_accuracy: 0.8271 - val_acc: 0.6015 - lr: 4.4695e-05\nEpoch 87/100\n166/166 [==============================] - 21s 129ms/step - loss: 1.3214 - sparse_top_k_categorical_accuracy: 0.8886 - acc: 0.6260 - val_loss: 1.7247 - val_sparse_top_k_categorical_accuracy: 0.8273 - val_acc: 0.6060 - lr: 3.5756e-05\nEpoch 88/100\n166/166 [==============================] - ETA: 0s - loss: 1.3228 - sparse_top_k_categorical_accuracy: 0.8876 - acc: 0.6277\nEpoch 88: ReduceLROnPlateau reducing learning rate to 2.8604481485672295e-05.\n166/166 [==============================] - 22s 131ms/step - loss: 1.3228 - sparse_top_k_categorical_accuracy: 0.8876 - acc: 0.6277 - val_loss: 1.7246 - val_sparse_top_k_categorical_accuracy: 0.8277 - val_acc: 0.6036 - lr: 3.5756e-05\nEpoch 89/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.3191 - sparse_top_k_categorical_accuracy: 0.8897 - acc: 0.6252 - val_loss: 1.7230 - val_sparse_top_k_categorical_accuracy: 0.8265 - val_acc: 0.6033 - lr: 2.8604e-05\nEpoch 90/100\n166/166 [==============================] - 22s 130ms/step - loss: 1.3107 - sparse_top_k_categorical_accuracy: 0.8900 - acc: 0.6294 - val_loss: 1.7238 - val_sparse_top_k_categorical_accuracy: 0.8275 - val_acc: 0.6030 - lr: 2.8604e-05\nEpoch 91/100\n166/166 [==============================] - ETA: 0s - loss: 1.3116 - sparse_top_k_categorical_accuracy: 0.8893 - acc: 0.6274\nEpoch 91: ReduceLROnPlateau reducing learning rate to 2.2883585188537836e-05.\n166/166 [==============================] - 21s 127ms/step - loss: 1.3116 - sparse_top_k_categorical_accuracy: 0.8893 - acc: 0.6274 - val_loss: 1.7257 - val_sparse_top_k_categorical_accuracy: 0.8271 - val_acc: 0.6047 - lr: 2.8604e-05\nEpoch 92/100\n166/166 [==============================] - 21s 127ms/step - loss: 1.3114 - sparse_top_k_categorical_accuracy: 0.8896 - acc: 0.6298 - val_loss: 1.7250 - val_sparse_top_k_categorical_accuracy: 0.8271 - val_acc: 0.6037 - lr: 2.2884e-05\nEpoch 93/100\n166/166 [==============================] - 21s 126ms/step - loss: 1.3061 - sparse_top_k_categorical_accuracy: 0.8898 - acc: 0.6297 - val_loss: 1.7222 - val_sparse_top_k_categorical_accuracy: 0.8273 - val_acc: 0.6024 - lr: 2.2884e-05\nEpoch 94/100\n166/166 [==============================] - 21s 127ms/step - loss: 1.3094 - sparse_top_k_categorical_accuracy: 0.8902 - acc: 0.6276 - val_loss: 1.7241 - val_sparse_top_k_categorical_accuracy: 0.8276 - val_acc: 0.6019 - lr: 2.2884e-05\nEpoch 95/100\n166/166 [==============================] - ETA: 0s - loss: 1.3010 - sparse_top_k_categorical_accuracy: 0.8912 - acc: 0.6307\nEpoch 95: ReduceLROnPlateau reducing learning rate to 1.830686815083027e-05.\n166/166 [==============================] - 22s 130ms/step - loss: 1.3010 - sparse_top_k_categorical_accuracy: 0.8912 - acc: 0.6307 - val_loss: 1.7227 - val_sparse_top_k_categorical_accuracy: 0.8277 - val_acc: 0.6042 - lr: 2.2884e-05\nEpoch 96/100\n166/166 [==============================] - 21s 128ms/step - loss: 1.3012 - sparse_top_k_categorical_accuracy: 0.8911 - acc: 0.6303 - val_loss: 1.7246 - val_sparse_top_k_categorical_accuracy: 0.8264 - val_acc: 0.6032 - lr: 1.8307e-05\nEpoch 97/100\n166/166 [==============================] - ETA: 0s - loss: 1.2953 - sparse_top_k_categorical_accuracy: 0.8930 - acc: 0.6299\nEpoch 97: ReduceLROnPlateau reducing learning rate to 1.4645494229625912e-05.\n166/166 [==============================] - 21s 127ms/step - loss: 1.2953 - sparse_top_k_categorical_accuracy: 0.8930 - acc: 0.6299 - val_loss: 1.7249 - val_sparse_top_k_categorical_accuracy: 0.8268 - val_acc: 0.6031 - lr: 1.8307e-05\nEpoch 98/100\n166/166 [==============================] - 22s 134ms/step - loss: 1.2906 - sparse_top_k_categorical_accuracy: 0.8932 - acc: 0.6340 - val_loss: 1.7238 - val_sparse_top_k_categorical_accuracy: 0.8275 - val_acc: 0.6043 - lr: 1.4645e-05\nEpoch 99/100\n166/166 [==============================] - ETA: 0s - loss: 1.2997 - sparse_top_k_categorical_accuracy: 0.8915 - acc: 0.6324\nEpoch 99: ReduceLROnPlateau reducing learning rate to 1.1716395238181577e-05.\n166/166 [==============================] - 21s 128ms/step - loss: 1.2997 - sparse_top_k_categorical_accuracy: 0.8915 - acc: 0.6324 - val_loss: 1.7237 - val_sparse_top_k_categorical_accuracy: 0.8285 - val_acc: 0.6041 - lr: 1.4645e-05\nEpoch 100/100\n166/166 [==============================] - 22s 131ms/step - loss: 1.2933 - sparse_top_k_categorical_accuracy: 0.8931 - acc: 0.6311 - val_loss: 1.7232 - val_sparse_top_k_categorical_accuracy: 0.8276 - val_acc: 0.6037 - lr: 1.1716e-05\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f78802f1180>"},"metadata":{}}]},{"cell_type":"code","source":"model1.save('/kaggle/working/Gru_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:36:13.350349Z","iopub.execute_input":"2023-09-12T16:36:13.350705Z","iopub.status.idle":"2023-09-12T16:36:13.506083Z","shell.execute_reply.started":"2023-09-12T16:36:13.350674Z","shell.execute_reply":"2023-09-12T16:36:13.505074Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model(\n    \"/kaggle/working/Gru_model.h5\",\n    custom_objects={'ChooseHand': ChooseHand, 'HandKineticLayer': HandKineticLayer, 'AngularLayer': AngularLayer, 'GatherLayer': GatherLayer, 'FaceKineticLayer' : FaceKineticLayer, 'MSD' : MSD}\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:41:32.243070Z","iopub.execute_input":"2023-09-12T16:41:32.243448Z","iopub.status.idle":"2023-09-12T16:41:48.428973Z","shell.execute_reply.started":"2023-09-12T16:41:32.243415Z","shell.execute_reply":"2023-09-12T16:41:48.427944Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model.predict(train_data[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T16:46:45.259767Z","iopub.execute_input":"2023-09-12T16:46:45.260127Z","iopub.status.idle":"2023-09-12T16:46:46.349415Z","shell.execute_reply.started":"2023-09-12T16:46:45.260097Z","shell.execute_reply":"2023-09-12T16:46:46.347845Z"},"trusted":true},"execution_count":30,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 0","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 0"],"ename":"KeyError","evalue":"0","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}